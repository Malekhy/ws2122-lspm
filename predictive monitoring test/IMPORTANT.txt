Steps:
----------
1- Train a prediction model with an original data (test.csv).
2- Train another prediction model with a preprocessed data (sampled model from LSPM tool and using different sampling methods).
3- Evalute both of the resulting models with the test data from the original log.



Notes: 
-----------
-we repeated step 2 with each sampled file according to the sampling method used to sampling that file.

-some parameters are modified
for example
keras.callbacks.EarlyStopping(monitor = val_loss)   --> keras.callbacks.EarlyStopping(monitor = loss)

-there was a number of problems regarding directory, thus,
these directories are modified such that the program can read the file and directory properly

-please refer to this link for more informations:
https://github.com/gyunamister/pm-prediction




Used commands:
---------------------
python train.py --status "o" --task "next_activity" --contextual_info False --num_epochs 10 --learning_rate 0.002 --num_folds 1 --batch_size 256 --data_set "test.csv" --data_dir "" --checkpoint_dir "" --control_flow_p True --time_p True --resource_p False --data_p False --transition False

python train.py --status "p" --task "next_activity" --contextual_info False --num_epochs 10 --learning_rate 0.002 --num_folds 1 --batch_size 256 --data_set "p_test.csv" --data_dir "" --p_data_set "p_test.csv.csv" --checkpoint_dir "" --control_flow_p True --time_p True --resource_p False --data_p False --transition False

python evaluate.py --status "o" --task "next_activity" --contextual_info False --num_epochs 10 --batch_size 256 --data_set "test.csv" --data_dir "../sample_data/" --checkpoint_dir "./checkpoints/" --control_flow_p True --time_p True --resource_p False --data_p False --transition False